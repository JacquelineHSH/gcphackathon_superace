{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into ‘/home/jupyter/.R/library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/home/jupyter/.R/library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n",
      "Installing package into ‘/home/jupyter/.R/library’\n",
      "(as ‘lib’ is unspecified)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages('dplyr')\n",
    "install.packages('ggplot2')\n",
    "install.packages('readr')\n",
    "install.packages('glmnet')\n",
    "install.packages('Metrics')\n",
    "install.packages('MLmetrics')\n",
    "install.packages('MASS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(dplyr)\n",
    "require(ggplot2)\n",
    "require(readr)\n",
    "require(glmnet)\n",
    "require(Metrics)\n",
    "require(MLmetrics)\n",
    "require(MASS)\n",
    "require(bigrquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide authentication to connect to BigQuery\n",
    "bq_auth(use_oob = TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the GCP project id\n",
    "projectid = \"gcphackathorn\"\n",
    "\n",
    "# Set your query\n",
    "sql <- \"SELECT * FROM dataset_final.final\"\n",
    "\n",
    "# Run query\n",
    "tb <- bq_project_query(projectid, sql)\n",
    "\n",
    "# Download query results\n",
    "df <- bq_table_download(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train <- df %>% \n",
    "  transmute(killings_hispanic,\n",
    "            year,\n",
    "            state,\n",
    "            poverty_rate,\n",
    "            poverty_male,\n",
    "            poverty_hispanic,\n",
    "            poverty_below_high_school,\n",
    "            male_perc = round(male/population*100,2),\n",
    "            hispanic_perc = round(hispanic/population*100,2),\n",
    "            below_high_school_perc = round(below_high_school/population*100,2),\n",
    "            unemployment_rate = round(unemployed/population*100,2),\n",
    "            killings_total\n",
    "          ) %>%\n",
    "    mutate(state = as.factor(state)) %>%\n",
    "         na.omit()   # remove rows with missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(Train) %>% as.data.frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating objects for regression\n",
    "y = as.numeric(Train$killings_hispanic)          # our y variable\n",
    "d = Train$poverty_hispanic                    # our treatment variable\n",
    "\n",
    "Train =  Train %>% dplyr::select(-killings_hispanic, -poverty_hispanic)    # remove y and d from Train \n",
    "X = model.matrix(d ~ ., Train) # select all variables and remove Intercept "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Causal Lasso\n",
    "\n",
    "## 1st Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages('doParallel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting lambda interval\n",
    "lamb_range = 10 ^ seq(1, -7, length= 100) \n",
    "\n",
    "Train2 = as.matrix(Train)\n",
    "### Runs CV - Lasso\n",
    "\n",
    "library(doParallel)\n",
    "registerDoParallel(5)\n",
    "set.seed(9547)\n",
    "cv_lasso= cv.glmnet(y = d, \n",
    "                    x = X, \n",
    "                    alpha = 1, \n",
    "                    nfolds = 5,\n",
    "                    lambda = lamb_range,\n",
    "                    standardize=TRUE,\n",
    "                    parallel=TRUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the MSE errors\n",
    "plot(cv_lasso)\n",
    "\n",
    "# Plots the Paths\n",
    "plot(cv_lasso$glmnet.fit, xvar=\"lambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimating D Hat\n",
    "\n",
    "### Retrieves the lambdas\n",
    "sd1_lambda = cv_lasso$lambda.1se\n",
    "\n",
    "# Mean squared errors from best lambdas\n",
    "print(cv_lasso$cvm[which(cv_lasso$lambda == cv_lasso$lambda.1se)])\n",
    "\n",
    "# In-sample dhats\n",
    "dhat_1se = predict(object = cv_lasso, s = \"lambda.1se\", newx = X)\n",
    "colnames(dhat_1se) <- \"dhat\"\n",
    "\n",
    "# Plot d against dhat\n",
    "plot(dhat_1se, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = cbind(dhat=dhat_1se, treatment = d, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave dhat unpenalized\n",
    "penalty_list = rep(1,ncol(X2))\n",
    "penalty_list[1] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run Lasso with dhat unpenalized\n",
    "set.seed(17)\n",
    "\n",
    "cv_lasso_final = cv.glmnet(y = y, \n",
    "                    x = X2, \n",
    "                    alpha = 1, \n",
    "                    nfolds = 5,\n",
    "                    penalty.factor = penalty_list,\n",
    "                    lambda = lamb_range,\n",
    "                    standardize=TRUE,\n",
    "                    parallel=TRUE)\n",
    "\n",
    "# Plots the MSE errors\n",
    "plot(cv_lasso_final)\n",
    "\n",
    "# Plots the Paths\n",
    "plot(cv_lasso_final$glmnet.fit, xvar=\"lambda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_lasso_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of variables selected by Lasso\n",
    "print(\"Total variables left:\")\n",
    "print(sum(coef(cv_lasso_final, select=\"1se\") != 0))    # 43 variables survived\n",
    "\n",
    "# Optimal lambda: \n",
    "lambda_final = cv_lasso_final$lambda.1se # 0.0053\n",
    "print(\"final lambda:\")\n",
    "print(lambda_final)\n",
    "\n",
    "#### !!! Coefficient of Degree variable after controlling for unpenalized dhat. \n",
    "impact = coef(cv_lasso_final, select = \"lambda.min\")[\"treatment\",]\n",
    "print('impact:')\n",
    "impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean The mean cross-validated error from best lambda\n",
    "cv_lasso_final$cvm[which(cv_lasso_final$lambda == cv_lasso_final$lambda.1se)]\n",
    "\n",
    "### AIC\n",
    "fit2 <- glmnet(y = y,\n",
    "               x = X2,\n",
    "               alpha = 1,\n",
    "               penalty.factor = penalty_list,\n",
    "               lambda = cv_lasso_final$lambda.1se,\n",
    "               standardize=TRUE)\n",
    "\n",
    "tLL2 <- fit2$nulldev - deviance(fit2)\n",
    "k2 <- fit2$df\n",
    "n2 <- fit2$nobs\n",
    "AICc2 <- -tLL2+2*k2+2*k2*(k2+1)/(n2-k2-1)\n",
    "AICc2\n",
    "\n",
    "fit2$dev.ratio  # considered R squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n <- nrow(X2)\n",
    "betas <- c()\n",
    "\n",
    "for(ind in 1:100){\n",
    "  print(ind)\n",
    "  sam_boot <- sample(1:n, n, replace=T)\n",
    "  lfit = glmnet(y = y[sam_boot], \n",
    "                x = X2[sam_boot,], \n",
    "                alpha = 1, \n",
    "                penalty.factor = penalty_list,\n",
    "                lambda = lambda_final,  # min lambda from 3rd question\n",
    "                standardize=TRUE)\n",
    "  degree_coef = coef(lfit)[\"treatment\",]\n",
    "  betas[ind] <- as.numeric(degree_coef)\n",
    "  \n",
    "}\n",
    "\n",
    "betas <- sort(betas)\n",
    "\n",
    "print(quantile(betas, c(.025, 0.975)))  # confidence interval\n",
    "\n",
    "# Print histogram of betas (booststrap)\n",
    "hist(betas, nclass = 20)\n",
    "abline(v=impact, col=2)\n",
    "\n",
    "boxplot(betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "r-cpu.3-6.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/r-cpu.3-6:m50"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
